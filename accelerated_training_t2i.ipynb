{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7804df82-9664-40c5-b6c8-c787c2037212",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03d2a93a-8a00-4de8-b4ad-bd0ce0ed082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import diffusers\n",
    "\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    T2IAdapter,\n",
    "    MultiAdapter,\n",
    "    StableDiffusionAdapterPipeline,\n",
    "    DDPMScheduler\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a35ba26-ddb4-40b4-b312-0ec96c4721f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import ProjectConfiguration, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8dd68-a17b-445e-befa-357c3f30d524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82cc191f-074b-4e42-91ee-5f2567a403a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from datasets import load_dataset\n",
    "\n",
    "#Generate an arg list \n",
    "\n",
    "args = SimpleNamespace()\n",
    "\n",
    "#Dataset generation args\n",
    "args.dataset_name = \"Overlapping triangles\"#\"fusing/fill50k\"\n",
    "args.train_data_dir = None #\"../ControlNet/training/fill50k\"\n",
    "args.dataset_config_name=None\n",
    "args.cache_dir = None\n",
    "args.image_column = \"image\"\n",
    "args.caption_column = \"text\"\n",
    "args.conditioning_image_column = \"conditioning_image\"\n",
    "args.resolution = 512\n",
    "args.max_train_samples = 1000\n",
    "args.seed = None\n",
    "args.train_batch_size = 4\n",
    "args.dataloader_num_workers = 0\n",
    "\n",
    "#Training args\n",
    "args.num_train_epochs = 10\n",
    "args.max_train_steps = 1000\n",
    "args.gradient_accumulation_steps = 1\n",
    "args.do_classifier_free_guidance= False\n",
    "args.validation_steps = 1\n",
    "args.set_grads_to_none = False\n",
    "#learning rate\n",
    "args.lr = 1e-4\n",
    "args.lr_scheduler = \"cosine\"\n",
    "args.lr_num_cycles = 1\n",
    "args.lr_power = 1\n",
    "args.lr_warmup_steps = 10\n",
    "\n",
    "#Validation args\n",
    "args.seed = None\n",
    "\n",
    "#adapter args\n",
    "args.adapter_conditioning_scale = 1.0\n",
    "args.num_images_per_prompt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418c0fc-770e-43dc-8849-34ba75385e59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00651edd-4743-425b-9d1d-faf0b7abea45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate base images first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4020bf-7bbf-418c-af38-1dd644e3c6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 511.5, 511.5, -0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate some generic training data real quick\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_triangle_sdf(H,W):\n",
    "    \n",
    "    \n",
    "    EPS = 1e-12\n",
    "    x_pos, y_pos = np.meshgrid(np.linspace(0, (H-1), H),np.linspace(0, (W-1), W))\n",
    "\n",
    "    thresh = int(.2*W)\n",
    "    len_thresh = thresh*2\n",
    "    img_np = np.zeros((H, W), dtype=np.uint8)\n",
    "    valid2 = False\n",
    "    valid3 = False\n",
    "    while valid2 == False or valid3 == False:\n",
    "        x_1 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_1 = int(np.random.uniform(thresh,W-thresh))\n",
    "\n",
    "        #Compute a second point for the triangle\n",
    "        x_2 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_2 = int(np.random.uniform(thresh,W-thresh))\n",
    "        idx = 0 \n",
    "        while np.linalg.norm(np.array([x_1,y_1]) - np.array([x_2,y_2])) < len_thresh:\n",
    "            if idx < 50:\n",
    "                x_2 = int(np.random.uniform(thresh,H-thresh))\n",
    "                y_2 = int(np.random.uniform(thresh,W-thresh))\n",
    "                valid2 = True\n",
    "            else:\n",
    "                valid2 = False\n",
    "                break\n",
    "\n",
    "        x_3 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_3 = int(np.random.uniform(thresh,W-thresh))\n",
    "        idx = 0\n",
    "        while (np.linalg.norm(np.array([x_1,y_1]) - np.array([x_3,y_3])) < len_thresh) or (np.linalg.norm(np.array([x_2,y_2]) - np.array([x_3,y_3])) < len_thresh):\n",
    "            idx = idx +1\n",
    "            if idx < 50:\n",
    "                x_3 = int(np.random.uniform(thresh,H-thresh))\n",
    "                y_3 = int(np.random.uniform(thresh,W-thresh)) \n",
    "                valid3 = True\n",
    "            else:\n",
    "                valid3 = False\n",
    "                break\n",
    "    \n",
    "    pts_inp = np.array([[x_1, y_1], [x_2, y_2], [x_3, y_3]])\n",
    "    \n",
    "    oop_normal = [0,0,1]\n",
    "    \n",
    "    n = np.cross([x_1-x_2,y_1-y_2,0], [x_3-x_2,y_3-y_2])\n",
    "    \n",
    "    if np.dot(n,oop_normal) < 0:\n",
    "        pts_inp = pts_inp[[0,2,1],:]\n",
    "        x_2,y_2 = pts_inp[1,:]\n",
    "        x_3,y_3 = pts_inp[2,:]\n",
    "        \n",
    "    normals = []\n",
    "    ix_12 = np.linspace(x_1,x_2,500)\n",
    "    m_12 = (y_2-y_1)/(x_2-x_1 + EPS)\n",
    "    iy_12 = y_2 + m_12*(ix_12 - x_2)\n",
    "    out_12 =  np.array([[x, y] for (x, y) in zip(ix_12, iy_12)])\n",
    "    norm_12 = [np.arctan2(y_2-y_1, x_2-x_1)+np.pi/2] * len(ix_12)\n",
    "    normals.extend(norm_12)\n",
    "    \n",
    "    ix_23 = np.linspace(x_2,x_3,500)\n",
    "    m_23 = (y_3-y_2)/(x_3-x_2 + EPS)\n",
    "    iy_23 = y_3 + m_23*(ix_23 - x_3)\n",
    "    out_23 =  np.array([[x, y] for (x, y) in zip(ix_23, iy_23)])\n",
    "    norm_23 = [np.arctan2(y_3-y_2, x_3-x_2)+np.pi/2] * len(ix_23)\n",
    "    normals.extend(norm_23)\n",
    "    \n",
    "    ix_31 = np.linspace(x_3,x_1,500)\n",
    "    m_31 = (y_1-y_3)/(x_1-x_3 + EPS)\n",
    "    iy_31 = y_1 + m_31*(ix_31 - x_1)\n",
    "    out_31 =  np.array([[x, y] for (x, y) in zip(ix_31, iy_31)])\n",
    "    norm_31 = [np.arctan2(y_1-y_3, x_1-x_3)+np.pi/2] * len(ix_31)\n",
    "    normals.extend(norm_31)\n",
    "    \n",
    "    #Combine all 3 ouputs\n",
    "    out_pts = np.concatenate([out_12,out_23,out_31],axis=0)\n",
    "    out_pts = out_pts.reshape((1, -1, 2))\n",
    "\n",
    "    \n",
    "    pts = pts_inp.reshape((1,-1,2))\n",
    "    cv2.fillPoly(img_np, pts, color=255, lineType=cv2.LINE_AA)\n",
    "    img = img_np.reshape(img_np.shape[0],img_np.shape[1],1)\n",
    "    img = np.asarray(img/255.0,dtype=np.float32)\n",
    "    img = np.asarray(img>.5,dtype=np.float32)\n",
    "    normals = np.asarray(normals)\n",
    "    \n",
    "    return img, out_pts, normals\n",
    "\n",
    "H=W=512\n",
    "\n",
    "img,out_pts,normals = generate_triangle_sdf(H,W)\n",
    "img = 1- img\n",
    "first_img = (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "plt.imshow(first_img)\n",
    "\n",
    "mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "\n",
    "masked_img = np.copy(img)\n",
    "masked_img[mask_img==1] = .5\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow((np.repeat(masked_img,3,-1)* 255).astype(np.uint8),cmap='gray_r')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(131)\n",
    "fg_layer = mask_img\n",
    "plt.imshow(fg_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(132)\n",
    "mid_layer = (1-img).squeeze()\n",
    "plt.imshow(mid_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(133)\n",
    "bg_layer = np.ones(mid_layer.shape)\n",
    "plt.imshow(bg_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.figure()\n",
    "layer_img = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "plt.imshow(layer_img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7077a8-9412-47a9-8962-21976d5cdcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=1000\n",
    "H=W=512\n",
    "\n",
    "layer_binaries = []\n",
    "layer_imgs = []\n",
    "base_imgs = []\n",
    "\n",
    "def gray2rgb(img):\n",
    "    return (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "\n",
    "for itr in range(DATASET_SIZE):\n",
    "    img,_,_ = generate_triangle_sdf(H,W)\n",
    "    img = 1- img\n",
    "    \n",
    "    #Mask (foreground layer)\n",
    "    mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "    mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "    #Plain background layer\n",
    "    bg_layer = np.ones([H,W])\n",
    "    \n",
    "    #Compositing full image\n",
    "    masked_img = np.copy(img)\n",
    "    masked_img[mask_img==1] = .5\n",
    "    \n",
    "    #Compositing layer map\n",
    "    fg_layer = mask_img\n",
    "    mid_layer = (1-img).squeeze()\n",
    "    layer_bin = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "\n",
    "    #add to lists\n",
    "    layer_binaries.append(layer_bin)\n",
    "    layer_imgs.append((gray2rgb(1-fg_layer[...,np.newaxis]*.5),\n",
    "                       gray2rgb(1-mid_layer[...,np.newaxis]),\n",
    "                       gray2rgb(bg_layer[...,np.newaxis])))\n",
    "    base_imgs.append(gray2rgb(masked_img))\n",
    "    \n",
    "    if itr%200 == 0:\n",
    "        print(itr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b489f3-4420-48e6-81b3-5ed9846fc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Also need to generate some utils for the training for the layering maps\n",
    "# # For example need some code that combines all layer maps below a layer and all above a layer\n",
    "# # Also need analagous code that does this for the layered  objects in the image\n",
    "\n",
    "# def get_front_layers(layer_imgs, layer_bin, layer_no):\n",
    "#     num_layers = len(layer_imgs) -1 #subtract 1 for loops??\n",
    "#     front_layers = np.ones(layer_imgs[0].shape)\n",
    "#     front_bin = np.zeros(layer_bin.shape)\n",
    "#     if layer_no == num_layers:\n",
    "#         return front_layers,front_bin\n",
    "#     else:\n",
    "#         for layer_idx in range(layer_no,num_layers):\n",
    "#             front_layers[layer_bin==1,:] = layer_imgs[layer_bin==1,:]\n",
    "#             front_bin[layer_bin==1] = 1\n",
    "#         return front_layers,front_bin\n",
    "        \n",
    "\n",
    "# def get_back_layer(layer_imgs, layer_bin, layer_no):\n",
    "#     num_layers = len(layer_imgs) - 1\n",
    "#     back_layers = np.ones(layer_imgs[0].shape)\n",
    "#     back_bin = np.zeros(layer_bin.shape)\n",
    "#     for layer_idx in range(layer_no):\n",
    "#         #FINISH / FIX THIS CODE AT SOMEPOINT\n",
    "#         front_layers[layer_bin==1,:] = layer_imgs[layer_bin==1,:]\n",
    "#         front_bin[layer_bin==1] = 1\n",
    "#     return front_layers,front_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a5fc3-d250-440b-9553-d951055f9009",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Put data into dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a412e66a-6b81-44f0-9ffd-fbb4eae7ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image transforms\n",
    "\n",
    "image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(args.resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "conditioning_image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(args.resolution),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1d502d9c-7b20-4660-a885-419ba1e32030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class\n",
    "class LayerDataset(Dataset):\n",
    "    def __init__(self,base_imgs,layer_imgs):\n",
    "        self.data = list(zip(base_imgs,layer_imgs))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        prompt = 'an image'\n",
    "\n",
    "        source = item[0] #base image (full image) (conditional input)\n",
    "        target = item[1]*255 #First layer only\n",
    "        \n",
    "        #Convert to torch tensors\n",
    "        source = torch.tensor(source).permute(2,0,1)\n",
    "        target = torch.tensor(target[0]).permute(2,0,1)\n",
    "        \n",
    "        #Apply transforms to both images\n",
    "        source = conditioning_image_transforms(source)\n",
    "        target = image_transforms(target)\n",
    "\n",
    "        return dict(pixel_values=target, txt=prompt, conditioning_pixel_values=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ff8e0a6d-f125-4ae5-95a1-2cfa34d539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "\n",
    "    conditioning_pixel_values = torch.stack([example[\"conditioning_pixel_values\"] for example in examples])\n",
    "    conditioning_pixel_values = conditioning_pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "\n",
    "    # input_ids = torch.stack([example[\"input_ids\"] for example in examples])\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"conditioning_pixel_values\": conditioning_pixel_values,\n",
    "        # \"input_ids\": input_ids,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e9512576-262d-4e7a-8a66-3b681be37eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14aa575248b0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset =  LayerDataset(base_imgs,layer_imgs)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_dataset[0]['pixel_values'].permute(1,2,0)/ 2 + 1/2)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_dataset[0]['conditioning_pixel_values'].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f77162e9-bbd2-42a1-bdc0-02e5cfc3c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=args.train_batch_size,\n",
    "    num_workers=args.dataloader_num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbe135-bcc4-4c84-9089-4dc418a50204",
   "metadata": {},
   "source": [
    "### Create a subset of validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "485ca10c-44d7-4838-a7c1-4e1962644d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE=2\n",
    "H=W=512\n",
    "\n",
    "val_binaries = []\n",
    "val_layers = []\n",
    "val_imgs = []\n",
    "\n",
    "def gray2rgb(img):\n",
    "    return (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "\n",
    "for itr in range(VALIDATION_SIZE):\n",
    "    img,_,_ = generate_triangle_sdf(H,W)\n",
    "    img = 1- img\n",
    "    \n",
    "    #Mask (foreground layer)\n",
    "    mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "    mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "    #Plain background layer\n",
    "    bg_layer = np.ones([H,W])\n",
    "    \n",
    "    #Compositing full image\n",
    "    masked_img = np.copy(img)\n",
    "    masked_img[mask_img==1] = .5\n",
    "    \n",
    "    #Compositing layer map\n",
    "    fg_layer = mask_img\n",
    "    mid_layer = (1-img).squeeze()\n",
    "    layer_bin = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "\n",
    "    #add to lists\n",
    "    val_binaries.append(layer_bin)\n",
    "    val_layers.append((gray2rgb(1-fg_layer[...,np.newaxis]*.5),\n",
    "                       gray2rgb(1-mid_layer[...,np.newaxis]),\n",
    "                       gray2rgb(bg_layer[...,np.newaxis])))\n",
    "    val_imgs.append(gray2rgb(masked_img))\n",
    "    \n",
    "#     if itr%200 == 0:\n",
    "#         print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef6462ff-ea36-4ada-aa8f-6ac9de8eee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "val_imgs_PIL = []\n",
    "val_layers_PIL = []\n",
    "for idx in range(len(val_imgs)):\n",
    "    val_imgs_PIL.append(Image.fromarray(val_imgs[idx]))\n",
    "    val_layers_PIL.append(Image.fromarray(val_layers[idx][0]))\n",
    "\n",
    "args.validation_image = val_imgs_PIL\n",
    "args.validation_prompt = [\"\"]\n",
    "args.num_validation_images = VALIDATION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f563f67-4bb5-4321-9662-e8a183a106f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Hard code some things for getting the first layer of each val_layers for now\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(val_imgs_PIL[0])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(val_layers_PIL[0])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(val_imgs_PIL[1])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(val_layers_PIL[1])\n",
    "plt.xticks([]);plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd2b9610-2f38-4b33-b410-c640284e23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioning_image_transforms(np.array(val_imgs_PIL[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1cf04b-9400-4ba6-a406-2d65ba39c6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement the adapter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1817a7a-6ae8-4c74-93fe-dc36f318696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "## Network that takes 4 dimensional input and pushes it to 3 dimensions for the vae\n",
    "class ContractNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContractNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(4, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "\n",
    "## Network that takes 3 dimensional input and pushes it to 4 dimensions for model out\n",
    "class ExpandNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpandNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0d58bbfc-ec06-42ee-8f25-0e7b5b22e583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'adapter_weights', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'class_embeddings_concat', 'conv_out_kernel', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'dual_cross_attention', 'conv_in_kernel', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'time_embedding_act_fn', 'cross_attention_norm', 'timestep_post_act', 'mid_block_type', 'upcast_attention', 'resnet_skip_time_act', 'resnet_out_scale_factor', 'use_linear_projection', 'encoder_hid_dim', 'only_cross_attention', 'class_embed_type', 'num_class_embeds'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "{'sample_max_value', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type', 'prediction_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the two adapters and the pretrained model\n",
    "\n",
    "# An adapter that takes in the original image (or a subset of layers)\n",
    "RGB_adapter = T2IAdapter(channels_in=int(3), \n",
    "                       block_out_channels=[320, 640, 1280, 1280][:4], \n",
    "                       num_res_blocks=2, \n",
    "                       kernel_size=1, \n",
    "                       res_block_skip=True, \n",
    "                       use_conv=False)\n",
    "\n",
    "# An adapter that takes in the mask given by the layers above the current one\n",
    "mask_adapter = T2IAdapter(channels_in=int(1), \n",
    "                       block_out_channels=[320, 640, 1280, 1280][:4], \n",
    "                       num_res_blocks=2, \n",
    "                       kernel_size=1, \n",
    "                       res_block_skip=True, \n",
    "                       use_conv=False)\n",
    "\n",
    "#Combine them into a single adapter\n",
    "# adapter = MultiAdapter([RGB_adapter,mask_adapter])\n",
    "adapter = RGB_adapter\n",
    "\n",
    "#Instantiate the Convolutional layers\n",
    "# contract_layer = ContractNet()\n",
    "# expand_layer = ExpandNet()\n",
    "\n",
    "#Pretrained stable diffusion model that we will try not to touch (may end up changing the final conv_out though.\n",
    "#To be honest I am really hoping this works\n",
    "\n",
    "model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionAdapterPipeline.from_pretrained(model_name, torch_dtype=torch.float32).to('cuda')\n",
    "pipe.safety_checker = None\n",
    "\n",
    "vae = pipe.vae\n",
    "unet = pipe.unet\n",
    "\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(model_name, subfolder=\"scheduler\")\n",
    "\n",
    "# also get the clip model because it matters probably....\n",
    "\n",
    "#But looks like it may not work as just the model for training so we have to separate it into parts for training anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b858c58-d6e5-4006-8532-a35066896acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random point, what if I dont do anything about the masking etc, and just try and make a model that removes the top object in a scene, or like just tries to get the layer mappings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036cf0b-3ce3-44d4-b42b-154d20d29045",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e10a3-3e60-4314-806b-26bd3bd3c065",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TODO: Write a validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d903a7f3-9124-4b5a-8bea-814f144cf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_validation(pipe, adapter, args, step=0,accelerator=None):\n",
    "    print(f\"step = {step}\")\n",
    "\n",
    "    # controlnet = accelerator.unwrap_model(controlnet)\n",
    "\n",
    "    pipe.adapter = adapter\n",
    "    # pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "    # pipeline = pipeline.to(accelerator.device)\n",
    "    # pipeline.set_progress_bar_config(disable=True)\n",
    "\n",
    "#     if args.enable_xformers_memory_efficient_attention:\n",
    "#         pipeline.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "    if args.seed is None:\n",
    "        generator = None\n",
    "    else:\n",
    "        generator = torch.Generator(device=accelerator.device).manual_seed(args.seed)\n",
    "\n",
    "    if len(args.validation_image) == len(args.validation_prompt):\n",
    "        validation_images = args.validation_image\n",
    "        validation_prompts = args.validation_prompt\n",
    "    elif len(args.validation_image) == 1:\n",
    "        validation_images = args.validation_image * len(args.validation_prompt)\n",
    "        validation_prompts = args.validation_prompt\n",
    "    elif len(args.validation_prompt) == 1:\n",
    "        validation_images = args.validation_image\n",
    "        validation_prompts = args.validation_prompt * len(args.validation_image)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"number of `args.validation_image` and `args.validation_prompt` should be checked in `parse_args`\"\n",
    "        )\n",
    "\n",
    "    image_logs = []\n",
    "\n",
    "    for validation_prompt, validation_image in zip(validation_prompts, validation_images):\n",
    "        # validation_image = Image.open(validation_image).convert(\"RGB\")\n",
    "\n",
    "        images = []\n",
    "\n",
    "        for _ in range(args.num_validation_images):\n",
    "            with torch.autocast(\"cuda\"):\n",
    "                image = pipe(\n",
    "                    validation_prompt, validation_image, num_inference_steps=20, generator=generator\n",
    "                ).images[0]\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "        image_logs.append(\n",
    "            {\"validation_image\": validation_image, \"images\": images, \"validation_prompt\": validation_prompt}\n",
    "        )\n",
    "        \n",
    "    \n",
    "    for tracker in accelerator.trackers:\n",
    "        if tracker.name == \"tensorboard\":\n",
    "            for log in image_logs:\n",
    "                images = log[\"images\"]\n",
    "                validation_prompt = log[\"validation_prompt\"]\n",
    "                validation_image = log[\"validation_image\"]\n",
    "\n",
    "                formatted_images = []\n",
    "\n",
    "                formatted_images.append(np.asarray(validation_image))\n",
    "\n",
    "                for image in images:\n",
    "                    formatted_images.append(np.asarray(image))\n",
    "\n",
    "                formatted_images = np.stack(formatted_images)\n",
    "\n",
    "                tracker.writer.add_images(validation_prompt, formatted_images, step, dataformats=\"NHWC\")\n",
    "        elif tracker.name == \"wandb\":\n",
    "            formatted_images = []\n",
    "\n",
    "            for log in image_logs:\n",
    "                images = log[\"images\"]\n",
    "                validation_prompt = log[\"validation_prompt\"]\n",
    "                validation_image = log[\"validation_image\"]\n",
    "\n",
    "                formatted_images.append(wandb.Image(validation_image, caption=\"Controlnet conditioning\"))\n",
    "\n",
    "                for image in images:\n",
    "                    image = wandb.Image(image, caption=validation_prompt)\n",
    "                    formatted_images.append(image)\n",
    "\n",
    "            tracker.log({\"validation\": formatted_images})\n",
    "        else:\n",
    "            logger.warn(f\"image logging not implemented for {tracker.name}\")\n",
    "\n",
    "    return image_logs\n",
    "\n",
    "# Here I need to make a set of images \n",
    "# Looks like top row, validation image *2, next validation image *2, bottom row is outputs\n",
    "\n",
    "def save_image_logs(image_logs,step=0):\n",
    "    plt.figure()\n",
    "    plt.subplot(241)\n",
    "    plt.imshow(image_logs[0]['validation_image'])\n",
    "    plt.subplot(242)\n",
    "    plt.imshow(image_logs[0]['validation_image'])\n",
    "    plt.subplot(243)\n",
    "    plt.imshow(image_logs[1]['validation_image'])\n",
    "    plt.subplot(244)\n",
    "    plt.imshow(image_logs[1]['validation_image'])\n",
    "\n",
    "    plt.subplot(245)\n",
    "    plt.imshow(image_logs[0]['images'][0])\n",
    "    plt.subplot(246)\n",
    "    plt.imshow(image_logs[0]['images'][1])\n",
    "    plt.subplot(247)\n",
    "    plt.imshow(image_logs[1]['images'][0])\n",
    "    plt.subplot(248)\n",
    "    plt.imshow(image_logs[1]['images'][1])\n",
    "\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "\n",
    "    plt.savefig(f'test_logs/epoch_{step}_val.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d19bbe-9dd5-4be9-bf04-5920e16bf9d6",
   "metadata": {},
   "source": [
    "### Prepare the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1da31f96-7810-4672-a18c-4c495260d02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'types.SimpleNamespace'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'output_dir'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'types.SimpleNamespace'\u001b[0m object has no attribute \u001b[32m'output_dir'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the accelerator \n",
    "logging_dir = Path(args.output_dir, args.logging_dir)\n",
    "\n",
    "accelerator_project_config = ProjectConfiguration(project_dir=args.output_dir, logging_dir=logging_dir)\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    mixed_precision=args.mixed_precision,\n",
    "    log_with=args.report_to,\n",
    "    project_config=accelerator_project_config,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger.info(accelerator.state, main_process_only=False)\n",
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_warning()\n",
    "    diffusers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "    diffusers.utils.logging.set_verbosity_error()\n",
    "    \n",
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02b598-6e3f-4e60-96a0-1051c8f99c3c",
   "metadata": {},
   "source": [
    "### Actual training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "22b83ac8-25c0-42f8-82c0-0509f147bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put adapter on GPU / prepare accelerator\n",
    "vae.requires_grad_(False)\n",
    "# adapter = adapter.to(\"cuda\")\n",
    "adapter = accelerator.unwrap_model(adapter)\n",
    "adapter, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    adapter, optimizer, train_dataloader, lr_scheduler)\n",
    "\n",
    "#Set optimizer class\n",
    "optimizer_class = torch.optim.AdamW\n",
    "\n",
    "#Get parameters to optimize\n",
    "params_to_optimize = adapter.parameters()\n",
    "optimizer = optimizer_class(\n",
    "    params_to_optimize,\n",
    "    lr = args.lr\n",
    ") \n",
    "\n",
    "#Get lr scheduler = \n",
    "lr_scheduler = get_scheduler(\n",
    "    args.lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.lr_warmup_steps,# * args.gradient_accumulation_steps,\n",
    "    num_training_steps=args.max_train_steps,# * args.gradient_accumulation_steps,\n",
    "    num_cycles=args.lr_num_cycles,\n",
    "    power=args.lr_power,\n",
    ")\n",
    "\n",
    "# additional, try to figure out accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3fc73a99-6882-4914-ad29-e9e2c3693067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7875a7-36e7-479b-9d30-20249fe0fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2023 15:39:14 - INFO - __main__ - ***** Running training *****\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Num examples = 1000\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Num batches each epoch = 250\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Num Epochs = 10\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "06/22/2023 15:39:14 - INFO - __main__ -   Total optimization steps = 2500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fba6b73621a4fee8e4ec6d6c2ed5e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet.py\n",
    "#Set number of max train steps?\n",
    "args.max_train_steps = args.num_train_epochs * len(train_dataloader)\n",
    "\n",
    "\n",
    "# Train!\n",
    "total_batch_size = args.train_batch_size #* accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\"  Num batches each epoch = {len(train_dataloader)}\")\n",
    "logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {args.train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "global_step = 0\n",
    "first_epoch = 0\n",
    "\n",
    "initial_global_step = 0\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    range(0, args.max_train_steps),\n",
    "    initial=initial_global_step,\n",
    "    desc=\"Steps\",\n",
    "    # Only show the progress bar once on each machine.\n",
    "    # disable=not accelerator.is_local_main_process,\n",
    ")\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "image_logs = None\n",
    "for epoch in range(first_epoch, args.num_train_epochs):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        with accelerator.accumulate(adapter):\n",
    "            #### Convert images to latent space\n",
    "            #network that goes from four to three dimensions\n",
    "            # contract_in = contract_layer()\n",
    "            latents = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype).to('cuda')).latent_dist.sample()\n",
    "            latents = latents * vae.config.scaling_factor\n",
    "            # print('Latents calculated')\n",
    "\n",
    "            # Sample noise that we'll add to the latents\n",
    "            noise = torch.randn_like(latents)\n",
    "            bsz = latents.shape[0]\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "            timesteps = timesteps.long()\n",
    "            # print('Noise Generated')\n",
    "\n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "            # Get the text embedding for conditioning\n",
    "            prompt_embeds = pipe._encode_prompt(\n",
    "                \"\",\n",
    "                device=\"cuda\",\n",
    "                num_images_per_prompt = args.train_batch_size ,\n",
    "                do_classifier_free_guidance=args.do_classifier_free_guidance,\n",
    "                negative_prompt=None,\n",
    "                prompt_embeds=None,\n",
    "                negative_prompt_embeds=None,\n",
    "            )\n",
    "            # print('Prompt Embeddings Generated')\n",
    "\n",
    "            # Denoising loop\n",
    "            adapter_input = batch[\"conditioning_pixel_values\"].to(dtype=weight_dtype).to('cuda')\n",
    "            adapter_state = adapter(adapter_input)\n",
    "            for k, v in enumerate(adapter_state):\n",
    "                adapter_state[k] = v * args.adapter_conditioning_scale\n",
    "            if args.num_images_per_prompt > 1:\n",
    "                for k, v in enumerate(adapter_state):\n",
    "                    adapter_state[k] = v.repeat(args.num_images_per_prompt, 1, 1, 1)\n",
    "            if args.do_classifier_free_guidance:\n",
    "                for k, v in enumerate(adapter_state):\n",
    "                    adapter_state[k] = torch.cat([v] * 2, dim=0)\n",
    "            # print('Adapter values Generated')\n",
    "\n",
    "\n",
    "            ## expand the latents if we are doing classifier free guidance\n",
    "            latent_model_input = torch.cat([noisy_latents] * 2) if args.do_classifier_free_guidance else noisy_latents\n",
    "\n",
    "            # predict the noise residual\n",
    "            noise_pred = unet(\n",
    "                    latent_model_input,\n",
    "                    timesteps,\n",
    "                    encoder_hidden_states=prompt_embeds,\n",
    "                    cross_attention_kwargs=None,\n",
    "                    down_block_additional_residuals=[state.clone() for state in adapter_state],\n",
    "            ).sample\n",
    "\n",
    "            # print('Prediction complete')\n",
    "            # Get the target for loss depending on the prediction type\n",
    "            if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "                target = noise\n",
    "            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "                target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "            loss = F.mse_loss(noise_pred.float(), target.float(), reduction=\"mean\")\n",
    "            # print('loss computed')\n",
    "            # loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=args.set_grads_to_none)\n",
    "            \n",
    "\n",
    "        #Stuff here for accelerator\n",
    "        if accelerator.sync_gradients:\n",
    "            progress_bar.update(1)\n",
    "            global_step += 1\n",
    "            if accelerator.is_main_process:\n",
    "                #Code for saving checkpoints\n",
    "                pass\n",
    "                \n",
    "                \n",
    "        logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        accelerator.log(logs, step=global_step)\n",
    "    if epoch % 2 == 0:\n",
    "        val_out = log_validation(pipe, adapter, args)\n",
    "        save_image_logs(val_out,step=epoch)\n",
    "    if global_step >= args.max_train_steps:\n",
    "        break\n",
    "        \n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ed01fab-3c04-4360-a45a-c6e207b48f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2023 15:28:05 - WARNING - matplotlib.image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14aa57500100>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(train_dataset[0]['pixel_values'].permute(1,2,0))\n",
    "plt.imshow(train_dataset[0]['conditioning_pixel_values'].permute(1,2,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575327f-d6e2-43de-a2d1-abfc3e0fcb8b",
   "metadata": {},
   "source": [
    "### wandbstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b92e0662-e37d-4b22-9438-fe0d65e15421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n",
      "/bin/bash: d9387a82bf250d82223965b50544c06bfa6bf8bd: command not found\n"
     ]
    }
   ],
   "source": [
    "!wandb login\n",
    "!d9387a82bf250d82223965b50544c06bfa6bf8bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ae2dfd8-8c6c-4e12-bb8e-9c8cc4bd7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /n/home07/adamaraju/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login \"d9387a82bf250d82223965b50544c06bfa6bf8bd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0f7f844-2005-4149-bc99-63dd6118d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maneeldamaraju\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/n/home07/adamaraju/fasrc/diffusers-t2i-adapter/wandb/run-20230621_165637-ucb66kwj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aneeldamaraju/my-awesome-project/runs/ucb66kwj' target=\"_blank\">lunar-pond-1</a></strong> to <a href='https://wandb.ai/aneeldamaraju/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aneeldamaraju/my-awesome-project' target=\"_blank\">https://wandb.ai/aneeldamaraju/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aneeldamaraju/my-awesome-project/runs/ucb66kwj' target=\"_blank\">https://wandb.ai/aneeldamaraju/my-awesome-project/runs/ucb66kwj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.77963</td></tr><tr><td>loss</td><td>0.21944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-pond-1</strong> at: <a href='https://wandb.ai/aneeldamaraju/my-awesome-project/runs/ucb66kwj' target=\"_blank\">https://wandb.ai/aneeldamaraju/my-awesome-project/runs/ucb66kwj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230621_165637-ucb66kwj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "851c6452-de2f-42c7-801e-8349139dd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "args.output_dir = \"test_logs/test_out\"\n",
    "args.logging_dir = \"test_logs/test_logs\"\n",
    "\n",
    "args.gradient_accumulation_steps=1\n",
    "args.mixed_precision = None\n",
    "args.report_to = \"wandb\"\n",
    "args.push_to_hub = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cd8910f-f98b-4252-892d-2ecb21ab0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = Path(args.output_dir, args.logging_dir)\n",
    "accelerator_project_config = ProjectConfiguration(project_dir=args.output_dir, logging_dir=logging_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6d809df-5e7c-4c8d-b6af-b0da931b4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    mixed_precision=args.mixed_precision,\n",
    "    log_with=args.report_to,\n",
    "    project_config=accelerator_project_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "678e0aee-35e5-4d1a-aa8e-37a53e11454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b12836ee-2a48-4cb5-bd6b-cbe28f3387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "163a16b4-4301-4311-a2de-8c3916de2026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/21/2023 17:10:36 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger(__name__)\n",
    "logger.info(accelerator.state, main_process_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5678465-8af6-4f05-a2b0-cdee735c13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_warning()\n",
    "    diffusers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "    diffusers.utils.logging.set_verbosity_error()\n",
    "    \n",
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    if args.push_to_hub:\n",
    "        repo_id = create_repo(\n",
    "            repo_id=args.hub_model_id or Path(args.output_dir).name, exist_ok=True, token=args.hub_token\n",
    "        ).repo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92ac6bb1-72b6-4606-9267-35bf6ef8a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = accelerator.unwrap_model(adapter)\n",
    "adapter, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    adapter, optimizer, train_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e324056-4fbe-4d81-8ca4-49133210fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "    tracker_config = dict(vars(args))\n",
    "\n",
    "    # tensorboard cannot handle list types for config\n",
    "    tracker_config.pop(\"validation_prompt\")\n",
    "    tracker_config.pop(\"validation_image\")\n",
    "\n",
    "    accelerator.init_trackers(args.tracker_project_name, config=tracker_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db1274dc-459b-4010-aa15-3fd1b665f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.tracker_project_name = \"training_t2i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0edb02b-19ad-4f39-97b0-5f50af3d3609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator.trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55cff375-ec02-4f83-b5ab-5c12ae38a905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'fusing/fill50k',\n",
       " 'train_data_dir': None,\n",
       " 'dataset_config_name': None,\n",
       " 'cache_dir': None,\n",
       " 'image_column': 'image',\n",
       " 'caption_column': 'text',\n",
       " 'conditioning_image_column': 'conditioning_image',\n",
       " 'resolution': 512,\n",
       " 'max_train_samples': 1000,\n",
       " 'seed': None,\n",
       " 'train_batch_size': 4,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'num_train_epochs': 10,\n",
       " 'max_train_steps': 1000,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'do_classifier_free_guidance': False,\n",
       " 'validation_steps': 1,\n",
       " 'set_grads_to_none': False,\n",
       " 'lr_scheduler': 'constant',\n",
       " 'lr_num_cycles': 1,\n",
       " 'lr_power': 1,\n",
       " 'lr_warmup_steps': 10,\n",
       " 'adapter_conditioning_scale': 1.0,\n",
       " 'num_images_per_prompt': 1,\n",
       " 'num_validation_images': 2,\n",
       " 'output_dir': 'test_logs/test_out',\n",
       " 'logging_dir': 'test_logs/test_logs',\n",
       " 'mixed_precision': None,\n",
       " 'report_to': 'wandb',\n",
       " 'push_to_hun': False,\n",
       " 'push_to_hub': False,\n",
       " 'tracker_project_name': 'training_t2i'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7ed5a-0b8b-44c4-81bd-8e4d714d4e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

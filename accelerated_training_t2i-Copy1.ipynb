{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7804df82-9664-40c5-b6c8-c787c2037212",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d2a93a-8a00-4de8-b4ad-bd0ce0ed082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/adamaraju/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import diffusers\n",
    "\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    T2IAdapter,\n",
    "    MultiAdapter,\n",
    "    StableDiffusionAdapterPipeline,\n",
    "    DDPMScheduler\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a35ba26-ddb4-40b4-b312-0ec96c4721f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import ProjectConfiguration, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e8dd68-a17b-445e-befa-357c3f30d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thing to do for tomorrow, create a new learning rate that mimics the one from the t2i paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cc191f-074b-4e42-91ee-5f2567a403a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from datasets import load_dataset\n",
    "\n",
    "#Generate an arg list \n",
    "\n",
    "args = SimpleNamespace()\n",
    "\n",
    "#Dataset generation args\n",
    "args.dataset_name = \"Double GPU tests\"#\"fusing/fill50k\"\n",
    "args.train_data_dir = None #\"../ControlNet/training/fill50k\"\n",
    "args.dataset_config_name=None\n",
    "args.cache_dir = None\n",
    "args.image_column = \"image\"\n",
    "args.caption_column = \"text\"\n",
    "args.conditioning_image_column = \"conditioning_image\"\n",
    "args.resolution = 512\n",
    "args.max_train_samples = 1000\n",
    "args.seed = None\n",
    "args.train_batch_size = 4\n",
    "args.dataloader_num_workers = 0\n",
    "\n",
    "#Training args\n",
    "args.num_train_epochs = 10\n",
    "args.max_train_steps = 1000\n",
    "args.gradient_accumulation_steps = 1\n",
    "args.do_classifier_free_guidance= False\n",
    "args.validation_steps = 1\n",
    "args.set_grads_to_none = False\n",
    "#learning rate\n",
    "args.lr = 1e-5\n",
    "args.lr_scheduler = \"constant\"\n",
    "args.lr_num_cycles = 1\n",
    "args.lr_power = 1\n",
    "args.lr_warmup_steps = 10\n",
    "\n",
    "#Validation args\n",
    "args.seed = None\n",
    "\n",
    "#adapter args\n",
    "args.adapter_conditioning_scale = 1.0\n",
    "args.num_images_per_prompt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418c0fc-770e-43dc-8849-34ba75385e59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00651edd-4743-425b-9d1d-faf0b7abea45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate base images first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4020bf-7bbf-418c-af38-1dd644e3c6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 511.5, 511.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate some generic training data real quick\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_triangle_sdf(H,W):\n",
    "    EPS = 1e-12\n",
    "    x_pos, y_pos = np.meshgrid(np.linspace(0, (H-1), H),np.linspace(0, (W-1), W))\n",
    "\n",
    "    thresh = int(.2*W)\n",
    "    len_thresh = thresh*2\n",
    "    img_np = np.zeros((H, W), dtype=np.uint8)\n",
    "    valid2 = False\n",
    "    valid3 = False\n",
    "    while valid2 == False or valid3 == False:\n",
    "        x_1 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_1 = int(np.random.uniform(thresh,W-thresh))\n",
    "\n",
    "        #Compute a second point for the triangle\n",
    "        x_2 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_2 = int(np.random.uniform(thresh,W-thresh))\n",
    "        idx = 0 \n",
    "        while np.linalg.norm(np.array([x_1,y_1]) - np.array([x_2,y_2])) < len_thresh:\n",
    "            if idx < 50:\n",
    "                x_2 = int(np.random.uniform(thresh,H-thresh))\n",
    "                y_2 = int(np.random.uniform(thresh,W-thresh))\n",
    "                valid2 = True\n",
    "            else:\n",
    "                valid2 = False\n",
    "                break\n",
    "\n",
    "        x_3 = int(np.random.uniform(thresh,H-thresh))\n",
    "        y_3 = int(np.random.uniform(thresh,W-thresh))\n",
    "        idx = 0\n",
    "        while (np.linalg.norm(np.array([x_1,y_1]) - np.array([x_3,y_3])) < len_thresh) or (np.linalg.norm(np.array([x_2,y_2]) - np.array([x_3,y_3])) < len_thresh):\n",
    "            idx = idx +1\n",
    "            if idx < 50:\n",
    "                x_3 = int(np.random.uniform(thresh,H-thresh))\n",
    "                y_3 = int(np.random.uniform(thresh,W-thresh)) \n",
    "                valid3 = True\n",
    "            else:\n",
    "                valid3 = False\n",
    "                break\n",
    "    \n",
    "    pts_inp = np.array([[x_1, y_1], [x_2, y_2], [x_3, y_3]])\n",
    "    \n",
    "    oop_normal = [0,0,1]\n",
    "    \n",
    "    n = np.cross([x_1-x_2,y_1-y_2,0], [x_3-x_2,y_3-y_2])\n",
    "    \n",
    "    if np.dot(n,oop_normal) < 0:\n",
    "        pts_inp = pts_inp[[0,2,1],:]\n",
    "        x_2,y_2 = pts_inp[1,:]\n",
    "        x_3,y_3 = pts_inp[2,:]\n",
    "        \n",
    "    normals = []\n",
    "    ix_12 = np.linspace(x_1,x_2,500)\n",
    "    m_12 = (y_2-y_1)/(x_2-x_1 + EPS)\n",
    "    iy_12 = y_2 + m_12*(ix_12 - x_2)\n",
    "    out_12 =  np.array([[x, y] for (x, y) in zip(ix_12, iy_12)])\n",
    "    norm_12 = [np.arctan2(y_2-y_1, x_2-x_1)+np.pi/2] * len(ix_12)\n",
    "    normals.extend(norm_12)\n",
    "    \n",
    "    ix_23 = np.linspace(x_2,x_3,500)\n",
    "    m_23 = (y_3-y_2)/(x_3-x_2 + EPS)\n",
    "    iy_23 = y_3 + m_23*(ix_23 - x_3)\n",
    "    out_23 =  np.array([[x, y] for (x, y) in zip(ix_23, iy_23)])\n",
    "    norm_23 = [np.arctan2(y_3-y_2, x_3-x_2)+np.pi/2] * len(ix_23)\n",
    "    normals.extend(norm_23)\n",
    "    \n",
    "    ix_31 = np.linspace(x_3,x_1,500)\n",
    "    m_31 = (y_1-y_3)/(x_1-x_3 + EPS)\n",
    "    iy_31 = y_1 + m_31*(ix_31 - x_1)\n",
    "    out_31 =  np.array([[x, y] for (x, y) in zip(ix_31, iy_31)])\n",
    "    norm_31 = [np.arctan2(y_1-y_3, x_1-x_3)+np.pi/2] * len(ix_31)\n",
    "    normals.extend(norm_31)\n",
    "    \n",
    "    #Combine all 3 ouputs\n",
    "    out_pts = np.concatenate([out_12,out_23,out_31],axis=0)\n",
    "    out_pts = out_pts.reshape((1, -1, 2))\n",
    "\n",
    "    \n",
    "    pts = pts_inp.reshape((1,-1,2))\n",
    "    cv2.fillPoly(img_np, pts, color=255, lineType=cv2.LINE_AA)\n",
    "    img = img_np.reshape(img_np.shape[0],img_np.shape[1],1)\n",
    "    img = np.asarray(img/255.0,dtype=np.float32)\n",
    "    img = np.asarray(img>.5,dtype=np.float32)\n",
    "    normals = np.asarray(normals)\n",
    "    \n",
    "    return img, out_pts, normals\n",
    "\n",
    "H=W=512\n",
    "\n",
    "img,out_pts,normals = generate_triangle_sdf(H,W)\n",
    "img = 1- img\n",
    "first_img = (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "plt.imshow(first_img)\n",
    "\n",
    "mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "\n",
    "masked_img = np.copy(img)\n",
    "masked_img[mask_img==1] = .5\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow((np.repeat(masked_img,3,-1)* 255).astype(np.uint8),cmap='gray_r')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(131)\n",
    "fg_layer = mask_img\n",
    "plt.imshow(fg_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(132)\n",
    "mid_layer = (1-img).squeeze()\n",
    "plt.imshow(mid_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(133)\n",
    "bg_layer = np.ones(mid_layer.shape)\n",
    "plt.imshow(bg_layer,cmap='gray',vmin=0,vmax=1)\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.figure()\n",
    "layer_img = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "plt.imshow(layer_img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7077a8-9412-47a9-8962-21976d5cdcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=1000\n",
    "H=W=512\n",
    "\n",
    "layer_binaries = []\n",
    "layer_imgs = []\n",
    "base_imgs = []\n",
    "\n",
    "def gray2rgb(img):\n",
    "    return (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "\n",
    "for itr in range(DATASET_SIZE):\n",
    "    img,_,_ = generate_triangle_sdf(H,W)\n",
    "    img = 1- img\n",
    "    \n",
    "    #Mask (foreground layer)\n",
    "    mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "    mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "    #Plain background layer\n",
    "    bg_layer = np.ones([H,W])\n",
    "    \n",
    "    #Compositing full image\n",
    "    masked_img = np.copy(img)\n",
    "    masked_img[mask_img==1] = .5\n",
    "    \n",
    "    #Compositing layer map\n",
    "    fg_layer = mask_img\n",
    "    mid_layer = (1-img).squeeze()\n",
    "    layer_bin = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "\n",
    "    #add to lists\n",
    "    layer_binaries.append(layer_bin)\n",
    "    layer_imgs.append((gray2rgb(1-fg_layer[...,np.newaxis]*.5),\n",
    "                       gray2rgb(1-mid_layer[...,np.newaxis]),\n",
    "                       gray2rgb(bg_layer[...,np.newaxis])))\n",
    "    base_imgs.append(gray2rgb(masked_img))\n",
    "    \n",
    "    if itr%200 == 0:\n",
    "        print(itr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b489f3-4420-48e6-81b3-5ed9846fc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Also need to generate some utils for the training for the layering maps\n",
    "# # For example need some code that combines all layer maps below a layer and all above a layer\n",
    "# # Also need analagous code that does this for the layered  objects in the image\n",
    "\n",
    "# def get_front_layers(layer_imgs, layer_bin, layer_no):\n",
    "#     num_layers = len(layer_imgs) -1 #subtract 1 for loops??\n",
    "#     front_layers = np.ones(layer_imgs[0].shape)\n",
    "#     front_bin = np.zeros(layer_bin.shape)\n",
    "#     if layer_no == num_layers:\n",
    "#         return front_layers,front_bin\n",
    "#     else:\n",
    "#         for layer_idx in range(layer_no,num_layers):\n",
    "#             front_layers[layer_bin==1,:] = layer_imgs[layer_bin==1,:]\n",
    "#             front_bin[layer_bin==1] = 1\n",
    "#         return front_layers,front_bin\n",
    "        \n",
    "\n",
    "# def get_back_layer(layer_imgs, layer_bin, layer_no):\n",
    "#     num_layers = len(layer_imgs) - 1\n",
    "#     back_layers = np.ones(layer_imgs[0].shape)\n",
    "#     back_bin = np.zeros(layer_bin.shape)\n",
    "#     for layer_idx in range(layer_no):\n",
    "#         #FINISH / FIX THIS CODE AT SOMEPOINT\n",
    "#         front_layers[layer_bin==1,:] = layer_imgs[layer_bin==1,:]\n",
    "#         front_bin[layer_bin==1] = 1\n",
    "#     return front_layers,front_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a5fc3-d250-440b-9553-d951055f9009",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Put data into dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a412e66a-6b81-44f0-9ffd-fbb4eae7ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image transforms\n",
    "\n",
    "image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(args.resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "conditioning_image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(args.resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(args.resolution),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d502d9c-7b20-4660-a885-419ba1e32030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class\n",
    "class LayerDataset(Dataset):\n",
    "    def __init__(self,base_imgs,layer_imgs):\n",
    "        self.data = list(zip(base_imgs,layer_imgs))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        prompt = 'an image'\n",
    "\n",
    "        source = item[0]\n",
    "        target = item[1]*255\n",
    "        \n",
    "        #Convert to torch tensors\n",
    "        source = torch.tensor(source).permute(2,0,1)\n",
    "        target = torch.tensor(target[0]).permute(2,0,1)\n",
    "        \n",
    "        #Apply transforms to both images\n",
    "        source = conditioning_image_transforms(source)\n",
    "        target = image_transforms(target)\n",
    "\n",
    "        return dict(pixel_values=target, txt=prompt, conditioning_pixel_values=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8e0a6d-f125-4ae5-95a1-2cfa34d539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "\n",
    "    conditioning_pixel_values = torch.stack([example[\"conditioning_pixel_values\"] for example in examples])\n",
    "    conditioning_pixel_values = conditioning_pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "\n",
    "    # input_ids = torch.stack([example[\"input_ids\"] for example in examples])\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"conditioning_pixel_values\": conditioning_pixel_values,\n",
    "        # \"input_ids\": input_ids,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9512576-262d-4e7a-8a66-3b681be37eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149440db4430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset =  LayerDataset(base_imgs,layer_imgs)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_dataset[0]['pixel_values'].permute(1,2,0)/ 2 + 1/2)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_dataset[0]['conditioning_pixel_values'].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f77162e9-bbd2-42a1-bdc0-02e5cfc3c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=args.train_batch_size,\n",
    "    num_workers=args.dataloader_num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbe135-bcc4-4c84-9089-4dc418a50204",
   "metadata": {},
   "source": [
    "### Create a subset of validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485ca10c-44d7-4838-a7c1-4e1962644d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE=2\n",
    "H=W=512\n",
    "\n",
    "val_binaries = []\n",
    "val_layers = []\n",
    "val_imgs = []\n",
    "\n",
    "def gray2rgb(img):\n",
    "    return (np.repeat(img,3,-1)* 255).astype(np.uint8)\n",
    "\n",
    "for itr in range(VALIDATION_SIZE):\n",
    "    img,_,_ = generate_triangle_sdf(H,W)\n",
    "    img = 1- img\n",
    "    \n",
    "    #Mask (foreground layer)\n",
    "    mask_img,_,_ = generate_triangle_sdf(H,W)\n",
    "    mask_img = mask_img[:,:,0].astype(int)\n",
    "\n",
    "    #Plain background layer\n",
    "    bg_layer = np.ones([H,W])\n",
    "    \n",
    "    #Compositing full image\n",
    "    masked_img = np.copy(img)\n",
    "    masked_img[mask_img==1] = .5\n",
    "    \n",
    "    #Compositing layer map\n",
    "    fg_layer = mask_img\n",
    "    mid_layer = (1-img).squeeze()\n",
    "    layer_bin = np.stack([fg_layer,mid_layer,bg_layer],axis=-1)\n",
    "\n",
    "    #add to lists\n",
    "    val_binaries.append(layer_bin)\n",
    "    val_layers.append((gray2rgb(1-fg_layer[...,np.newaxis]*.5),\n",
    "                       gray2rgb(1-mid_layer[...,np.newaxis]),\n",
    "                       gray2rgb(bg_layer[...,np.newaxis])))\n",
    "    val_imgs.append(gray2rgb(masked_img))\n",
    "    \n",
    "#     if itr%200 == 0:\n",
    "#         print(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6462ff-ea36-4ada-aa8f-6ac9de8eee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "val_imgs_PIL = []\n",
    "val_layers_PIL = []\n",
    "for idx in range(len(val_imgs)):\n",
    "    val_imgs_PIL.append(Image.fromarray(val_imgs[idx]))\n",
    "    val_layers_PIL.append(Image.fromarray(val_layers[idx][0]))\n",
    "\n",
    "args.validation_image = val_imgs_PIL\n",
    "args.validation_prompt = [\"\"]\n",
    "args.num_validation_images = VALIDATION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f563f67-4bb5-4321-9662-e8a183a106f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Hard code some things for getting the first layer of each val_layers for now\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(val_imgs_PIL[0])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(val_layers_PIL[0])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(val_imgs_PIL[1])\n",
    "plt.xticks([]);plt.yticks([]);\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(val_layers_PIL[1])\n",
    "plt.xticks([]);plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2b9610-2f38-4b33-b410-c640284e23c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149440c3a760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(conditioning_image_transforms(np.array(val_imgs_PIL[0])).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1cf04b-9400-4ba6-a406-2d65ba39c6a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement the adapter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1817a7a-6ae8-4c74-93fe-dc36f318696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "## Network that takes 4 dimensional input and pushes it to 3 dimensions for the vae\n",
    "class ContractNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContractNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(4, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "    \n",
    "\n",
    "## Network that takes 3 dimensional input and pushes it to 4 dimensions for model out\n",
    "class ExpandNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpandNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d58bbfc-ec06-42ee-8f25-0e7b5b22e583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the two adapters and the pretrained model\n",
    "\n",
    "# An adapter that takes in the original image (or a subset of layers)\n",
    "RGB_adapter = T2IAdapter(channels_in=int(3), \n",
    "                       block_out_channels=[320, 640, 1280, 1280][:4], \n",
    "                       num_res_blocks=2, \n",
    "                       kernel_size=1, \n",
    "                       res_block_skip=True, \n",
    "                       use_conv=False)\n",
    "\n",
    "# An adapter that takes in the mask given by the layers above the current one\n",
    "mask_adapter = T2IAdapter(channels_in=int(1), \n",
    "                       block_out_channels=[320, 640, 1280, 1280][:4], \n",
    "                       num_res_blocks=2, \n",
    "                       kernel_size=1, \n",
    "                       res_block_skip=True, \n",
    "                       use_conv=False)\n",
    "\n",
    "#Combine them into a single adapter\n",
    "# adapter = MultiAdapter([RGB_adapter,mask_adapter])\n",
    "adapter = RGB_adapter\n",
    "\n",
    "#Instantiate the Convolutional layers\n",
    "# contract_layer = ContractNet()\n",
    "# expand_layer = ExpandNet()\n",
    "\n",
    "#Pretrained stable diffusion model that we will try not to touch (may end up changing the final conv_out though.\n",
    "#To be honest I am really hoping this works\n",
    "\n",
    "model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionAdapterPipeline.from_pretrained(model_name, torch_dtype=torch.float32).to(\"cuda\")\n",
    "pipe.safety_checker = None\n",
    "\n",
    "vae = pipe.vae\n",
    "unet = pipe.unet\n",
    "\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(model_name, subfolder=\"scheduler\")\n",
    "\n",
    "# also get the clip model because it matters probably....\n",
    "\n",
    "#But looks like it may not work as just the model for training so we have to separate it into parts for training anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b858c58-d6e5-4006-8532-a35066896acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random point, what if I dont do anything about the masking etc, and just try and make a model that removes the top object in a scene, or like just tries to get the layer mappings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036cf0b-3ce3-44d4-b42b-154d20d29045",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e10a3-3e60-4314-806b-26bd3bd3c065",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TODO: Write a validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d903a7f3-9124-4b5a-8bea-814f144cf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_validation(pipe, adapter, args, step=0,accelerator=None):\n",
    "    print(f\"step = {step}\")\n",
    "\n",
    "    # controlnet = accelerator.unwrap_model(controlnet)\n",
    "\n",
    "    pipe.adapter = adapter\n",
    "    # pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "    # pipeline = pipeline.to(accelerator.device)\n",
    "    # pipeline.set_progress_bar_config(disable=True)\n",
    "\n",
    "#     if args.enable_xformers_memory_efficient_attention:\n",
    "#         pipeline.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "    if args.seed is None:\n",
    "        generator = None\n",
    "    else:\n",
    "        generator = torch.Generator(device=accelerator.device).manual_seed(args.seed)\n",
    "\n",
    "    if len(args.validation_image) == len(args.validation_prompt):\n",
    "        validation_images = args.validation_image\n",
    "        validation_prompts = args.validation_prompt\n",
    "    elif len(args.validation_image) == 1:\n",
    "        validation_images = args.validation_image * len(args.validation_prompt)\n",
    "        validation_prompts = args.validation_prompt\n",
    "    elif len(args.validation_prompt) == 1:\n",
    "        validation_images = args.validation_image\n",
    "        validation_prompts = args.validation_prompt * len(args.validation_image)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"number of `args.validation_image` and `args.validation_prompt` should be checked in `parse_args`\"\n",
    "        )\n",
    "\n",
    "    image_logs = []\n",
    "\n",
    "    for validation_prompt, validation_image in zip(validation_prompts, validation_images):\n",
    "        # validation_image = Image.open(validation_image).convert(\"RGB\")\n",
    "\n",
    "        images = []\n",
    "\n",
    "        for _ in range(args.num_validation_images):\n",
    "            with torch.autocast(\"cuda\"):\n",
    "                image = pipe(\n",
    "                    validation_prompt, validation_image, num_inference_steps=20, generator=generator\n",
    "                ).images[0]\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "        image_logs.append(\n",
    "            {\"validation_image\": validation_image, \"images\": images, \"validation_prompt\": validation_prompt}\n",
    "        )\n",
    "        \n",
    "    \n",
    "    for tracker in accelerator.trackers:\n",
    "        if tracker.name == \"tensorboard\":\n",
    "            for log in image_logs:\n",
    "                images = log[\"images\"]\n",
    "                validation_prompt = log[\"validation_prompt\"]\n",
    "                validation_image = log[\"validation_image\"]\n",
    "\n",
    "                formatted_images = []\n",
    "\n",
    "                formatted_images.append(np.asarray(validation_image))\n",
    "\n",
    "                for image in images:\n",
    "                    formatted_images.append(np.asarray(image))\n",
    "\n",
    "                formatted_images = np.stack(formatted_images)\n",
    "\n",
    "                tracker.writer.add_images(validation_prompt, formatted_images, step, dataformats=\"NHWC\")\n",
    "        elif tracker.name == \"wandb\":\n",
    "            formatted_images = []\n",
    "\n",
    "            for log in image_logs:\n",
    "                images = log[\"images\"]\n",
    "                validation_prompt = log[\"validation_prompt\"]\n",
    "                validation_image = log[\"validation_image\"]\n",
    "\n",
    "                formatted_images.append(wandb.Image(validation_image, caption=\"Controlnet conditioning\"))\n",
    "\n",
    "                for image in images:\n",
    "                    image = wandb.Image(image, caption=validation_prompt)\n",
    "                    formatted_images.append(image)\n",
    "\n",
    "            tracker.log({\"validation\": formatted_images})\n",
    "        else:\n",
    "            logger.warn(f\"image logging not implemented for {tracker.name}\")\n",
    "\n",
    "    return image_logs\n",
    "\n",
    "# Here I need to make a set of images \n",
    "# Looks like top row, validation image *2, next validation image *2, bottom row is outputs\n",
    "\n",
    "def save_image_logs(image_logs,step=0):\n",
    "    plt.figure()\n",
    "    plt.subplot(241)\n",
    "    plt.imshow(image_logs[0]['validation_image'])\n",
    "    plt.subplot(242)\n",
    "    plt.imshow(image_logs[0]['validation_image'])\n",
    "    plt.subplot(243)\n",
    "    plt.imshow(image_logs[1]['validation_image'])\n",
    "    plt.subplot(244)\n",
    "    plt.imshow(image_logs[1]['validation_image'])\n",
    "\n",
    "    plt.subplot(245)\n",
    "    plt.imshow(image_logs[0]['images'][0])\n",
    "    plt.subplot(246)\n",
    "    plt.imshow(image_logs[0]['images'][1])\n",
    "    plt.subplot(247)\n",
    "    plt.imshow(image_logs[1]['images'][0])\n",
    "    plt.subplot(248)\n",
    "    plt.imshow(image_logs[1]['images'][1])\n",
    "\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "\n",
    "    plt.savefig(f'test_logs/epoch_{step}_val.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d19bbe-9dd5-4be9-bf04-5920e16bf9d6",
   "metadata": {},
   "source": [
    "### Prepare the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9e0c18b-8adb-4fa4-8b84-61a7772ca3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "\n",
    "args.output_dir = \"test_logs/test_out\"\n",
    "args.logging_dir = \"test_logs/test_logs\"\n",
    "args.tracker_project_name = \"scratch cubic testing\"#\"cubic timestep sampling\"\n",
    "\n",
    "args.gradient_accumulation_steps=1\n",
    "args.mixed_precision = None\n",
    "args.report_to = \"wandb\"\n",
    "args.push_to_hub = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1da31f96-7810-4672-a18c-4c495260d02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /n/home07/adamaraju/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "!wandb login \"d9387a82bf250d82223965b50544c06bfa6bf8bd\"\n",
    "\n",
    "#Initialize the accelerator \n",
    "def init_accelerator():\n",
    "    logging_dir = Path(args.output_dir, args.logging_dir)\n",
    "\n",
    "    accelerator_project_config = ProjectConfiguration(project_dir=args.output_dir, logging_dir=logging_dir)\n",
    "\n",
    "    accelerator = Accelerator(\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        mixed_precision=args.mixed_precision,\n",
    "        log_with=args.report_to,\n",
    "        project_config=accelerator_project_config,\n",
    "    )\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "\n",
    "    logger = get_logger(__name__)\n",
    "    logger.info(accelerator.state, main_process_only=False)\n",
    "    logger.info(accelerator.state, main_process_only=False)\n",
    "    if accelerator.is_local_main_process:\n",
    "        transformers.utils.logging.set_verbosity_warning()\n",
    "        diffusers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "        diffusers.utils.logging.set_verbosity_error()\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        if args.output_dir is not None:\n",
    "            os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        tracker_config = dict(vars(args))\n",
    "\n",
    "        # tensorboard cannot handle list types for config\n",
    "        tracker_config.pop(\"validation_prompt\")\n",
    "        tracker_config.pop(\"validation_image\")\n",
    "\n",
    "        accelerator.init_trackers(args.tracker_project_name, config=tracker_config)\n",
    "    return accelerator, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb088a5-8227-4c3c-b83f-2879ecb1cea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f9f845-db5e-4c67-b062-31895856bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if version.parse(accelerate.__version__) >= version.parse(\"0.16.0\"):\n",
    "#     # create custom saving & loading hooks so that `accelerator.save_state(...)` serializes in a nice format\n",
    "#     def save_model_hook(models, weights, output_dir):\n",
    "#         i = len(weights) - 1\n",
    "\n",
    "#         while len(weights) > 0:\n",
    "#             weights.pop()\n",
    "#             model = models[i]\n",
    "\n",
    "#             sub_dir = \"adapter\"\n",
    "#             model.save_pretrained(os.path.join(output_dir, sub_dir))\n",
    "\n",
    "#             i -= 1\n",
    "\n",
    "# #     def load_model_hook(models, input_dir):\n",
    "# #         while len(models) > 0:\n",
    "# #             # pop models so that they are not loaded again\n",
    "# #             model = models.pop()\n",
    "\n",
    "# #             # load diffusers style into model\n",
    "# #             load_model = ControlNetModel.from_pretrained(input_dir, subfolder=\"controlnet\")\n",
    "# #             model.register_to_config(**load_model.config)\n",
    "\n",
    "# #             model.load_state_dict(load_model.state_dict())\n",
    "# #             del load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02b598-6e3f-4e60-96a0-1051c8f99c3c",
   "metadata": {},
   "source": [
    "### Actual training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22b83ac8-25c0-42f8-82c0-0509f147bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put adapter on GPU / prepare accelerator\n",
    "vae.requires_grad_(False)\n",
    "adapter = adapter.to(\"cuda\")\n",
    "# adapter = accelerator.unwrap_model(adapter)\n",
    "\n",
    "\n",
    "#Set optimizer class\n",
    "optimizer_class = torch.optim.AdamW\n",
    "\n",
    "#Get parameters to optimize\n",
    "params_to_optimize = adapter.parameters()\n",
    "optimizer = optimizer_class(\n",
    "    params_to_optimize,\n",
    "    lr = args.lr\n",
    ") \n",
    "\n",
    "#Get lr scheduler = \n",
    "lr_scheduler = get_scheduler(\n",
    "    args.lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.lr_warmup_steps,# * args.gradient_accumulation_steps,\n",
    "    num_training_steps=args.max_train_steps,# * args.gradient_accumulation_steps,\n",
    "    num_cycles=args.lr_num_cycles,\n",
    "    power=args.lr_power,\n",
    ")\n",
    "# additional, try to figure out accelerator\n",
    "\n",
    "# adapter, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "#     adapter, optimizer, train_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fc73a99-6882-4914-ad29-e9e2c3693067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7875a7-36e7-479b-9d30-20249fe0fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/24/2023 14:03:51 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "06/24/2023 14:03:51 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "06/24/2023 14:03:52 - ERROR - wandb.jupyter - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maneeldamaraju\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/n/home07/adamaraju/fasrc/diffusers-t2i-adapter/wandb/run-20230624_140356-96hnr9i0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing/runs/96hnr9i0' target=\"_blank\">fresh-fire-2</a></strong> to <a href='https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing' target=\"_blank\">https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing/runs/96hnr9i0' target=\"_blank\">https://wandb.ai/aneeldamaraju/scratch%20cubic%20testing/runs/96hnr9i0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/24/2023 14:04:03 - INFO - __main__ - ***** Running training *****\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Num examples = 1000\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Num batches each epoch = 250\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Num Epochs = 10\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "06/24/2023 14:04:03 - INFO - __main__ -   Total optimization steps = 2500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2944fb882746e9b3e8b43db84b4a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## https://github.com/huggingface/diffusers/blob/main/examples/controlnet/train_controlnet.py\n",
    "#Set number of max train steps?\n",
    "# def training_loop():\n",
    "#initialize the accelerator\n",
    "accelerator, logger = init_accelerator()\n",
    "adapter = accelerator.unwrap_model(adapter)\n",
    "adapter, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    adapter, optimizer, train_dataloader, lr_scheduler)\n",
    "\n",
    "args.max_train_steps = args.num_train_epochs * len(train_dataloader)\n",
    "\n",
    "# Train!\n",
    "total_batch_size = args.train_batch_size #* accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\"  Num batches each epoch = {len(train_dataloader)}\")\n",
    "logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {args.train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "global_step = 0\n",
    "first_epoch = 0\n",
    "\n",
    "initial_global_step = 0\n",
    "\n",
    "progress_bar = tqdm(\n",
    "    range(0, args.max_train_steps),\n",
    "    initial=initial_global_step,\n",
    "    desc=\"Steps\",\n",
    "    # Only show the progress bar once on each machine.\n",
    "    # disable=not accelerator.is_local_main_process,\n",
    ")\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "image_logs = None\n",
    "for epoch in range(first_epoch, args.num_train_epochs):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        with accelerator.accumulate(adapter):\n",
    "            #### Convert images to latent space\n",
    "            #network that goes from four to three dimensions\n",
    "            # contract_in = contract_layer()\n",
    "            latents = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype).to('cuda')).latent_dist.sample()\n",
    "            latents = latents * vae.config.scaling_factor\n",
    "            # print('Latents calculated')\n",
    "\n",
    "            # Sample noise that we'll add to the latents\n",
    "            noise = torch.randn_like(latents)\n",
    "            bsz = latents.shape[0]\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "            timesteps = (1 - (timesteps/ noise_scheduler.config.num_train_timesteps)**3) *  noise_scheduler.config.num_train_timesteps\n",
    "            timesteps = timesteps.to(torch.int).clamp(0,noise_scheduler.config.num_train_timesteps-1).to(latents.device).long()\n",
    "            # timesteps = timesteps.long()\n",
    "            # print('Noise Generated')\n",
    "\n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "            # Get the text embedding for conditioning\n",
    "            prompt_embeds = pipe._encode_prompt(\n",
    "                \"\",\n",
    "                device=\"cuda\",\n",
    "                num_images_per_prompt = args.train_batch_size ,\n",
    "                do_classifier_free_guidance=args.do_classifier_free_guidance,\n",
    "                negative_prompt=None,\n",
    "                prompt_embeds=None,\n",
    "                negative_prompt_embeds=None,\n",
    "            )\n",
    "            # print('Prompt Embeddings Generated')\n",
    "\n",
    "            # Denoising loop\n",
    "            adapter_input = batch[\"conditioning_pixel_values\"].to(dtype=weight_dtype).to('cuda')\n",
    "            adapter_state = adapter(adapter_input)\n",
    "            for k, v in enumerate(adapter_state):\n",
    "                adapter_state[k] = v * args.adapter_conditioning_scale\n",
    "            if args.num_images_per_prompt > 1:\n",
    "                for k, v in enumerate(adapter_state):\n",
    "                    adapter_state[k] = v.repeat(args.num_images_per_prompt, 1, 1, 1)\n",
    "            if args.do_classifier_free_guidance:\n",
    "                for k, v in enumerate(adapter_state):\n",
    "                    adapter_state[k] = torch.cat([v] * 2, dim=0)\n",
    "            # print('Adapter values Generated')\n",
    "\n",
    "\n",
    "            ## expand the latents if we are doing classifier free guidance\n",
    "            latent_model_input = torch.cat([noisy_latents] * 2) if args.do_classifier_free_guidance else noisy_latents\n",
    "\n",
    "            # predict the noise residual\n",
    "            noise_pred = unet(\n",
    "                    latent_model_input,\n",
    "                    timesteps,\n",
    "                    encoder_hidden_states=prompt_embeds,\n",
    "                    cross_attention_kwargs=None,\n",
    "                    down_block_additional_residuals=[state.clone() for state in adapter_state],\n",
    "            ).sample\n",
    "\n",
    "            # print('Prediction complete')\n",
    "            # Get the target for loss depending on the prediction type\n",
    "            if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "                target = noise\n",
    "            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "                target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "            loss = F.mse_loss(noise_pred.float(), target.float(), reduction=\"mean\")\n",
    "            # print('loss computed')\n",
    "            # loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=args.set_grads_to_none)\n",
    "\n",
    "\n",
    "        #Stuff here for accelerator\n",
    "        if accelerator.sync_gradients:\n",
    "            progress_bar.update(1)\n",
    "            global_step += 1\n",
    "            if accelerator.is_main_process:\n",
    "                #Code for saving checkpoints\n",
    "                pass\n",
    "\n",
    "\n",
    "        logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        accelerator.log(logs, step=global_step)\n",
    "    if epoch % 2 == 0:\n",
    "        val_out = log_validation(pipe, adapter, args, accelerator = accelerator)\n",
    "        save_image_logs(val_out,step=epoch)\n",
    "    if global_step >= args.max_train_steps:\n",
    "        break\n",
    "\n",
    "accelerator.end_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054eebaf-7a92-45ab-bd9f-2f6e460cf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from accelerate.utils import write_basic_config\n",
    "\n",
    "# write_basic_config()  # Write a config file\n",
    "# os._exit(00)  # Restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd8a5b-dd9e-47af-9b8b-86f9836f0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd5d4f-78bd-486d-8fa1-b9512a144eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from accelerate import notebook_launcher\n",
    "\n",
    "# notebook_launcher(training_loop, num_processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575327f-d6e2-43de-a2d1-abfc3e0fcb8b",
   "metadata": {},
   "source": [
    "### wandbstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e0662-e37d-4b22-9438-fe0d65e15421",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login\n",
    "!d9387a82bf250d82223965b50544c06bfa6bf8bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2dfd8-8c6c-4e12-bb8e-9c8cc4bd7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "!wandb login \"d9387a82bf250d82223965b50544c06bfa6bf8bd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7f844-2005-4149-bc99-63dd6118d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c6452-de2f-42c7-801e-8349139dd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "args.output_dir = \"test_logs/test_out\"\n",
    "args.logging_dir = \"test_logs/test_logs\"\n",
    "\n",
    "args.gradient_accumulation_steps=1\n",
    "args.mixed_precision = None\n",
    "args.report_to = \"wandb\"\n",
    "args.push_to_hub = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8910f-f98b-4252-892d-2ecb21ab0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = Path(args.output_dir, args.logging_dir)\n",
    "accelerator_project_config = ProjectConfiguration(project_dir=args.output_dir, logging_dir=logging_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d809df-5e7c-4c8d-b6af-b0da931b4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    mixed_precision=args.mixed_precision,\n",
    "    log_with=args.report_to,\n",
    "    project_config=accelerator_project_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e0aee-35e5-4d1a-aa8e-37a53e11454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12836ee-2a48-4cb5-bd6b-cbe28f3387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a16b4-4301-4311-a2de-8c3916de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "logger.info(accelerator.state, main_process_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5678465-8af6-4f05-a2b0-cdee735c13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_warning()\n",
    "    diffusers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "    diffusers.utils.logging.set_verbosity_error()\n",
    "    \n",
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    if args.push_to_hub:\n",
    "        repo_id = create_repo(\n",
    "            repo_id=args.hub_model_id or Path(args.output_dir).name, exist_ok=True, token=args.hub_token\n",
    "        ).repo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac6bb1-72b6-4606-9267-35bf6ef8a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = accelerator.unwrap_model(adapter)\n",
    "adapter, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    adapter, optimizer, train_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e324056-4fbe-4d81-8ca4-49133210fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.tracker_project_name = \"double gpu test\"\n",
    "if accelerator.is_main_process:\n",
    "    tracker_config = dict(vars(args))\n",
    "\n",
    "    # tensorboard cannot handle list types for config\n",
    "    tracker_config.pop(\"validation_prompt\")\n",
    "    tracker_config.pop(\"validation_image\")\n",
    "\n",
    "    accelerator.init_trackers(args.tracker_project_name, config=tracker_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1274dc-459b-4010-aa15-3fd1b665f749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0edb02b-19ad-4f39-97b0-5f50af3d3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cff375-ec02-4f83-b5ab-5c12ae38a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7ed5a-0b8b-44c4-81bd-8e4d714d4e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
